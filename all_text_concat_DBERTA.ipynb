{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_text_concat_DBERTA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO12MbakO2HY9cQTTVOAuab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ba0267514b0446ba497ba1ee6ba3bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0121182c9b9040e38cd3619592f53b00",
              "IPY_MODEL_fa5034fa12f546fe82eba9bb89c728c9",
              "IPY_MODEL_7648479b67ca4bfc9a23843875759351"
            ],
            "layout": "IPY_MODEL_626ea9cde25f4d139ed3ca0cd9792819"
          }
        },
        "0121182c9b9040e38cd3619592f53b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2801319de77d4eb884936fa3cf36b888",
            "placeholder": "​",
            "style": "IPY_MODEL_533ab52c758442518af6566513c11762",
            "value": "100%"
          }
        },
        "fa5034fa12f546fe82eba9bb89c728c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beacae856e78459595df3656a6ffff1c",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2260d4d30df426c9dc29f0c96d15e37",
            "value": 4
          }
        },
        "7648479b67ca4bfc9a23843875759351": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca3d0d7aa3574ccf9d698fde181b33c7",
            "placeholder": "​",
            "style": "IPY_MODEL_a7fd5d653cd54633a038f729eba4a0d4",
            "value": " 4/4 [00:07&lt;00:00,  1.66s/ba]"
          }
        },
        "626ea9cde25f4d139ed3ca0cd9792819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2801319de77d4eb884936fa3cf36b888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533ab52c758442518af6566513c11762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beacae856e78459595df3656a6ffff1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2260d4d30df426c9dc29f0c96d15e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca3d0d7aa3574ccf9d698fde181b33c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fd5d653cd54633a038f729eba4a0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03c0bda30b3846cfbfe1399a7cad132e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f774f911f26c4f468d6722784c4038ec",
              "IPY_MODEL_208bfdecb0f64e639e2c7c9c965cca78",
              "IPY_MODEL_6d1d03c6a03549b5b72c72db7dc8947e"
            ],
            "layout": "IPY_MODEL_b1df426b7e9c44dfba1661242bed0cb2"
          }
        },
        "f774f911f26c4f468d6722784c4038ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c72050f24f12497cba0e3151936fffb7",
            "placeholder": "​",
            "style": "IPY_MODEL_b992a3e9f72d49bd9303a4d1289c9e97",
            "value": "100%"
          }
        },
        "208bfdecb0f64e639e2c7c9c965cca78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3022067934f4b31b8cd75d23c1b4300",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b709fff1ee5343fbbb76a2d803de20e0",
            "value": 1
          }
        },
        "6d1d03c6a03549b5b72c72db7dc8947e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c36b8283f2c468097819b6df10148e6",
            "placeholder": "​",
            "style": "IPY_MODEL_dbb00680fe584850b3a9c8b19f20ed1c",
            "value": " 1/1 [00:00&lt;00:00, 15.18ba/s]"
          }
        },
        "b1df426b7e9c44dfba1661242bed0cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72050f24f12497cba0e3151936fffb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b992a3e9f72d49bd9303a4d1289c9e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3022067934f4b31b8cd75d23c1b4300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b709fff1ee5343fbbb76a2d803de20e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c36b8283f2c468097819b6df10148e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb00680fe584850b3a9c8b19f20ed1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/feedback-prize-effectiveness/blob/main/all_text_concat_DBERTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vAwrF3S24Hzn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try: import fastkaggle\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -Uq fastkaggle\n",
        "\n",
        "!pip install -Uq datasets\n",
        "!pip install -Uq transformers\n",
        "!pip install -Uq sentencepiece \n",
        "!pip install -Uq pynvml\n",
        "!pip install -Uq evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastkaggle import *\n",
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "J0E4FZde4QB3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config depending on whether this is running on kaggle or collab\n",
        "# is_colab = True\n",
        "is_colab = not os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "comp = 'feedback-prize-effectiveness'\n",
        "if is_colab:\n",
        "    model_save_path = Path('/content/'+comp+'_out/models')\n",
        "else:\n",
        "    model_save_path = Path('/kaggle/working/'+comp) #+'/models')"
      ],
      "metadata": {
        "id": "LwaMmLpipyJd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if is_colab:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "CIpACVZUk0VM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import colab libraries\n",
        "if is_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UOjHaaj64SAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dac7831-f1b1-4458-e822-b8e932ce3161"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so lets move it there.\n",
        "if is_colab:\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/Kaggle_api_auth/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Rv1FT2oS4X_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7844a33c-033b-425a-861c-8fc245238f23"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "if is_colab:\n",
        "    !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SM6uBIQ34eqk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = setup_comp(comp)\n",
        "path"
      ],
      "metadata": {
        "id": "Ikwoyt764icQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7492d98-dfc8-461d-c0c6-0a991ffa55ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('feedback-prize-effectiveness')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text classification"
      ],
      "metadata": {
        "id": "_WyXQ4ySSyUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def file_read(file_path):\n",
        "    with open(file_path, 'r') as _f: \n",
        "        all_content = _f.read()\n",
        "    return all_content"
      ],
      "metadata": {
        "id": "DaZzI-zTqNSx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process text - add all columns \n",
        "df = pd.read_csv(path/'train.csv')\n",
        "df['essay_text'] = df['essay_id'].apply(lambda x: file_read(path / 'train' / f'{x}.txt'))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XY6PVulLoZFY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1759aaf2-458c-490d-adbc-e204f68a2c7b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   discourse_id      essay_id  \\\n",
              "0  0013cc385424  007ACE74B050   \n",
              "1  9704a709b505  007ACE74B050   \n",
              "2  c22adee811b6  007ACE74B050   \n",
              "3  a10d361e54e4  007ACE74B050   \n",
              "4  db3e453ec4e2  007ACE74B050   \n",
              "\n",
              "                                      discourse_text discourse_type  \\\n",
              "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
              "1  On my perspective, I think that the face is a ...       Position   \n",
              "2  I think that the face is a natural landform be...          Claim   \n",
              "3  If life was on Mars, we would know by now. The...       Evidence   \n",
              "4  People thought that the face was formed by ali...   Counterclaim   \n",
              "\n",
              "  discourse_effectiveness                                         essay_text  \n",
              "0                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "1                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "2                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "3                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "4                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-352e52bb-71b5-46df-a776-17492b183cb1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>essay_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0013cc385424</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9704a709b505</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c22adee811b6</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a10d361e54e4</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>If life was on Mars, we would know by now. The...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>db3e453ec4e2</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>People thought that the face was formed by ali...</td>\n",
              "      <td>Counterclaim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-352e52bb-71b5-46df-a776-17492b183cb1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-352e52bb-71b5-46df-a776-17492b183cb1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-352e52bb-71b5-46df-a776-17492b183cb1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See sequence length\n",
        "df['seq_length_essay'] = [len(txt.split()) for txt in df['essay_text'].tolist()]\n",
        "df['seq_length_dis'] = [len(txt.split()) for txt in df['discourse_text'].tolist()]\n",
        "df['seq_length_essay'].describe(), df['seq_length_dis'].describe()"
      ],
      "metadata": {
        "id": "k__FA3GVwqeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03226cff-7b14-4dd8-f4a7-4389aa6cf9ab"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(count    36765.000000\n",
              " mean       458.588522\n",
              " std        220.423420\n",
              " min        144.000000\n",
              " 25%        288.000000\n",
              " 50%        408.000000\n",
              " 75%        579.000000\n",
              " max       1367.000000\n",
              " Name: seq_length_essay, dtype: float64, count    36765.000000\n",
              " mean        44.654073\n",
              " std         46.669682\n",
              " min          1.000000\n",
              " 25%         16.000000\n",
              " 50%         28.000000\n",
              " 75%         57.000000\n",
              " max        836.000000\n",
              " Name: seq_length_dis, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace discorse text within the context text as __MASKED__\n",
        "df['masked_ess_txt'] = df[['essay_text','discourse_text']].apply(lambda row: row.essay_text.strip().replace(row.discourse_text.strip(),\n",
        "                                                                                                         '__MASKED__'),\n",
        "                                                              axis = 1)\n",
        "df['seq_length_mask_ess'] = [len(txt.split()) for txt in df['masked_ess_txt'].tolist()]\n",
        "df['masked_ess_txt'].head(), df['seq_length_mask_ess'].describe()"
      ],
      "metadata": {
        "id": "ZSq5YwUFHsgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab435cbc-4eee-42ca-f3e6-10b8f2ed619c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    __MASKED__ On my perspective, I think that the...\n",
              " 1    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 2    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 3    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 4    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " Name: masked_ess_txt, dtype: object, count    36765.000000\n",
              " mean       414.791024\n",
              " std        213.788307\n",
              " min          1.000000\n",
              " 25%        254.000000\n",
              " 50%        367.000000\n",
              " 75%        531.000000\n",
              " max       1345.000000\n",
              " Name: seq_length_mask_ess, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to truncate discourse text and context text\n",
        "# this is still in progress\n",
        "# def trunc_text(text, num_words, unique_centre_tok = None):\n",
        "#     w_l = text.split()\n",
        "#     if unique_centre_tok is None:\n",
        "#         if len(w_l) > num_words: w_l = w_l[:num_words]\n",
        "#     else:\n",
        "#         if len(w_l) > num_words:\n",
        "#             try: pos_tok = w_l.index(unique_centre_tok) + 1\n",
        "#             except: # in case there is an issue with the replacement\n",
        "#                 print(text)\n",
        "#                 pos_tok = round(num_words / 2)\n",
        "#             if pos_tok > round(len(w_l) / 2):\n",
        "#                 if len(w_l) > pos_tok + round((num_words - 1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words - 1) / 2) - 1\n",
        "#                 else:\n",
        "#                     start_pos = len(w_l) - num_words\n",
        "#                 w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#             else:\n",
        "#                 if pos_tok > round((num_words -1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words -1) / 2) - 1\n",
        "#                     w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#                 else:\n",
        "#                     w_l = w_l[:num_words]\n",
        "            \n",
        "#     return ' '.join(w_l)\n",
        "\n",
        "# [trunc_text(\"let's see where __MASKED__ we are going.\", i, unique_centre_tok = \"__MASKED__\") for i in range(2,8)]"
      ],
      "metadata": {
        "id": "VFLhCiRbrWKG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all text columns for classification \n",
        "# concat all\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text + '; DISCOURSE: ' + df.discourse_text + '; TYPE: ' + df.discourse_type\n",
        "\n",
        "# concat after truncation\n",
        "# df['essay_text_trunc'] = df.masked_ess_txt.apply(lambda t: trunc_text(t,512, \"__MASKED__\"))\n",
        "# df['discourse_text_trunc'] = df.discourse_text.apply(lambda t: trunc_text(t,64))\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text_trunc + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text_trunc \n",
        "df['input'] = 'CONTEXT: ' + df.masked_ess_txt + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text\n",
        "df['seq_length_input'] = [len(txt.split()) for txt in df['input'].tolist()]\n",
        "df['seq_length_input'].describe()"
      ],
      "metadata": {
        "id": "xy67RMN42OSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09227697-a5ba-4681-92db-d139baaed8d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    36765.000000\n",
              "mean       463.536244\n",
              "std        220.382475\n",
              "min        149.000000\n",
              "25%        293.000000\n",
              "50%        413.000000\n",
              "75%        584.000000\n",
              "max       1373.000000\n",
              "Name: seq_length_input, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampling to test in collab\n",
        "if is_colab: df = df.sample(frac=0.10)\n",
        "df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVB7CqH6HVe3",
        "outputId": "d95ce2bb-b737-455e-8ac8-3e4a6b9a8e4b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3676"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create data datasets\n",
        "from datasets import Dataset,DatasetDict\n",
        "ds = Dataset.from_pandas(df)\n",
        "ds"
      ],
      "metadata": {
        "id": "SpWa5edK5ac1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4159d37-b3ea-4829-feee-8fed2bcd6d6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'input', 'seq_length_input', '__index_level_0__'],\n",
              "    num_rows: 3676\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "from datasets import ClassLabel\n",
        "labels = ClassLabel(names=df.discourse_effectiveness.unique().tolist())"
      ],
      "metadata": {
        "id": "DWXrIMfaE0xr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nm = 'microsoft/deberta-v3-small'"
      ],
      "metadata": {
        "id": "V2bnJl5Ie2KP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer, DataCollatorWithPadding\n",
        "tokz = AutoTokenizer.from_pretrained(model_nm)"
      ],
      "metadata": {
        "id": "pEDjRQnlhDqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce9ee1c-bdab-484f-fcb0-99e1dce8680c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.model_max_length, tokz.is_fast"
      ],
      "metadata": {
        "id": "6MESpUL477PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095addcd-937c-4a07-db29-e4dbe8a66bd9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000000000000000019884624838656, True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tok_func(batch, is_test = False): \n",
        "    tokens = tokz(batch[\"input\"], padding=\"longest\") #, truncation=True)\n",
        "    if not is_test:\n",
        "        tokens['labels'] = labels.str2int(batch['discourse_effectiveness'])\n",
        "        # [float(l) for l in labels.str2int(batch['discourse_effectiveness'])]\n",
        "    return tokens\n",
        "tok_ds = ds.map(tok_func, batched=True)"
      ],
      "metadata": {
        "id": "tMGkk70YhHDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0ba0267514b0446ba497ba1ee6ba3bdc",
            "0121182c9b9040e38cd3619592f53b00",
            "fa5034fa12f546fe82eba9bb89c728c9",
            "7648479b67ca4bfc9a23843875759351",
            "626ea9cde25f4d139ed3ca0cd9792819",
            "2801319de77d4eb884936fa3cf36b888",
            "533ab52c758442518af6566513c11762",
            "beacae856e78459595df3656a6ffff1c",
            "a2260d4d30df426c9dc29f0c96d15e37",
            "ca3d0d7aa3574ccf9d698fde181b33c7",
            "a7fd5d653cd54633a038f729eba4a0d4"
          ]
        },
        "outputId": "3ee82b78-1af4-4467-dd07-a613a63e4301"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ba0267514b0446ba497ba1ee6ba3bdc"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.num_classes, labels.names"
      ],
      "metadata": {
        "id": "P0dx_ObXYEQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec40d4de-c110-48c4-c6a7-510cffb84daf"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, ['Effective', 'Adequate', 'Ineffective'])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tok_ds = tok_ds.rename_columns({'discourse_effectiveness':'labels'})"
      ],
      "metadata": {
        "id": "Y7lT5AINvNLt"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# row = tok_ds[0]\n",
        "# row['input'], row['input_ids'], row['labels']"
      ],
      "metadata": {
        "id": "jJHfjPCq41Ov"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ],
      "metadata": {
        "id": "dfoZ3OGIkut4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c74f158-0411-471f-a111-fec55256e07a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'input', 'seq_length_input', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 2757\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'input', 'seq_length_input', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 919\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer, IntervalStrategy\n",
        "import evaluate\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1yO1kdpelBcn"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokz)"
      ],
      "metadata": {
        "id": "ftOtAxTECx-1"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 4\n",
        "grad_acc = 16\n",
        "epochs = 4\n",
        "lr = 5e-5\n",
        "metric_name = \"f1\"\n",
        "\n",
        "args = TrainingArguments('outputs',\n",
        "                         learning_rate=lr,\n",
        "                         warmup_ratio=0.1,\n",
        "                         lr_scheduler_type='cosine',\n",
        "                         fp16=True,\n",
        "                        evaluation_strategy=\"epoch\",\n",
        "                         logging_strategy = \"epoch\",\n",
        "                        #  logging_steps = 10,\n",
        "                        #  eval_steps = 10,\n",
        "                         per_device_train_batch_size=bs,\n",
        "                          per_device_eval_batch_size=bs*2,\n",
        "                        num_train_epochs=epochs,\n",
        "                          weight_decay=0.01,\n",
        "                         gradient_accumulation_steps=grad_acc,\n",
        "                        #   load_best_model_at_end=True,\n",
        "                            metric_for_best_model=metric_name,\n",
        "                        #  label_names = labels.names, # possibly this is messing up with metrics\n",
        "                          report_to='none')"
      ],
      "metadata": {
        "id": "129jbaWJlJ2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df2a052-f239-4188-94b1-ad8a546a1556"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "def report_gpu():\n",
        "    print(torch.cuda.list_gpu_processes())\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "L6RYU1RW6O48"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_gpu()"
      ],
      "metadata": {
        "id": "35s9cdAO6Wvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93cae8f5-5170-4872-fe76-322417489699"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU:0\n",
            "process      61761 uses    15413.000 MB GPU memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_nm, \n",
        "                                                           num_labels=labels.num_classes)\n",
        "def acc_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"f1\")\n",
        "    # metric = evaluate.load(\"accuracy\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions,\n",
        "                          references=labels,\n",
        "                          average = 'weighted')\n",
        "    # return {\"accuracy\": (predictions == labels).astype(np.float32).mean().item()}\n",
        "\n",
        "trainer = Trainer(model, args, \n",
        "                  train_dataset=dds['train'], \n",
        "                  eval_dataset=dds['test'],\n",
        "                  data_collator=data_collator,\n",
        "                  tokenizer=tokz,\n",
        "                  compute_metrics=acc_metrics)"
      ],
      "metadata": {
        "id": "yG50TpjnlZuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e901b4f-b776-4026-d1d7-0c37662e6461"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ce3185000148731a86ceaf533caa85fe513fc79e02b7fe5831fb1ed52a0e0d22.7e73b1561275ae3b633ba76ab7e4889d28d73dbcdc008cbc2414369b39da319b\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train();"
      ],
      "metadata": {
        "id": "U_MEO-4gl1YP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "5bf0c28a-cf86-40f7-d382-5e0f85437be4"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: masked_ess_txt, discourse_type, discourse_text, seq_length_input, essay_text, discourse_effectiveness, __index_level_0__, seq_length_essay, seq_length_mask_ess, input, essay_id, discourse_id, seq_length_dis. If masked_ess_txt, discourse_type, discourse_text, seq_length_input, essay_text, discourse_effectiveness, __index_level_0__, seq_length_essay, seq_length_mask_ess, input, essay_id, discourse_id, seq_length_dis are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2757\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 86\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='86' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [86/86 28:15, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.948200</td>\n",
              "      <td>0.779412</td>\n",
              "      <td>0.593373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.756600</td>\n",
              "      <td>0.736639</td>\n",
              "      <td>0.603832</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: masked_ess_txt, discourse_type, discourse_text, seq_length_input, essay_text, discourse_effectiveness, __index_level_0__, seq_length_essay, seq_length_mask_ess, input, essay_id, discourse_id, seq_length_dis. If masked_ess_txt, discourse_type, discourse_text, seq_length_input, essay_text, discourse_effectiveness, __index_level_0__, seq_length_essay, seq_length_mask_ess, input, essay_id, discourse_id, seq_length_dis are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 919\n",
            "  Batch size = 8\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: masked_ess_txt, discourse_type, discourse_text, seq_length_input, essay_text, discourse_effectiveness, __index_level_0__, seq_length_essay, seq_length_mask_ess, input, essay_id, discourse_id, seq_length_dis. If masked_ess_txt, discourse_type, discourse_text, seq_length_input, essay_text, discourse_effectiveness, __index_level_0__, seq_length_essay, seq_length_mask_ess, input, essay_id, discourse_id, seq_length_dis are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 919\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Y2OXrMe3aZ",
        "outputId": "fb86f762-92d0-45ef-a22e-ae22c5bf74ae"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/feedback-prize-effectiveness_out/models\n",
            "Configuration saved in /content/feedback-prize-effectiveness_out/models/config.json\n",
            "Model weights saved in /content/feedback-prize-effectiveness_out/models/pytorch_model.bin\n",
            "tokenizer config file saved in /content/feedback-prize-effectiveness_out/models/tokenizer_config.json\n",
            "Special tokens file saved in /content/feedback-prize-effectiveness_out/models/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test prediction"
      ],
      "metadata": {
        "id": "sY9r7pEQI_na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = pd.read_csv(path/'test.csv')\n",
        "# pre-process test df texts\n",
        "eval_df['essay_text'] = eval_df['essay_id'].apply(lambda x: file_read(path / 'test' / f'{x}.txt'))\n",
        "eval_df['masked_ess_txt'] = eval_df[['essay_text','discourse_text']].apply(lambda row: row.essay_text.strip().replace(row.discourse_text.strip(),\n",
        "                                                                                                         '__MASKED__'),\n",
        "                                                              axis = 1)\n",
        "eval_df['input'] = 'CONTEXT: ' + eval_df.masked_ess_txt + '; TYPE: ' + eval_df.discourse_type + '; DISCOURSE: ' + eval_df.discourse_text"
      ],
      "metadata": {
        "id": "66ZCDjawJPyp"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "tst_tok_func = partial(tok_func, is_test = True)\n",
        "eval_ds = Dataset.from_pandas(eval_df).map(tst_tok_func, batched=True)"
      ],
      "metadata": {
        "id": "X-UY7SRFJFfB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "03c0bda30b3846cfbfe1399a7cad132e",
            "f774f911f26c4f468d6722784c4038ec",
            "208bfdecb0f64e639e2c7c9c965cca78",
            "6d1d03c6a03549b5b72c72db7dc8947e",
            "b1df426b7e9c44dfba1661242bed0cb2",
            "c72050f24f12497cba0e3151936fffb7",
            "b992a3e9f72d49bd9303a4d1289c9e97",
            "c3022067934f4b31b8cd75d23c1b4300",
            "b709fff1ee5343fbbb76a2d803de20e0",
            "7c36b8283f2c468097819b6df10148e6",
            "dbb00680fe584850b3a9c8b19f20ed1c"
          ]
        },
        "outputId": "75b419d6-e534-4271-cafa-efb5b47a82e3"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03c0bda30b3846cfbfe1399a7cad132e"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(eval_ds).predictions\n",
        "preds.astype(float)"
      ],
      "metadata": {
        "id": "EPEQGpKBl_Fh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "d18ee366-b741-48bd-caed-36936b675122"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: masked_ess_txt, discourse_type, discourse_text, essay_text, input, essay_id, discourse_id. If masked_ess_txt, discourse_type, discourse_text, essay_text, input, essay_id, discourse_id are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 10\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.48876953,  0.78320312, -1.29199219],\n",
              "       [ 0.49682617,  0.77978516, -1.296875  ],\n",
              "       [ 0.50097656,  0.77929688, -1.30078125],\n",
              "       [ 0.47509766,  0.78466797, -1.28320312],\n",
              "       [ 0.46020508,  0.78613281, -1.27246094],\n",
              "       [ 0.48852539,  0.78125   , -1.29296875],\n",
              "       [ 0.50488281,  0.77832031, -1.3046875 ],\n",
              "       [ 0.49511719,  0.77978516, -1.296875  ],\n",
              "       [ 0.4921875 ,  0.78027344, -1.29492188],\n",
              "       [ 0.49121094,  0.78125   , -1.29394531]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LycepdfuZYj7",
        "outputId": "79eedb83-cc15-49f3-dc20-9aec823772a7"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/feedback-prize-effectiveness_out/models/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/feedback-prize-effectiveness_out/models\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaV2ForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file /content/feedback-prize-effectiveness_out/models/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
            "\n",
            "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /content/feedback-prize-effectiveness_out/models.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = eval_df['input'].tolist()\n",
        "inputs = tokz(raw_inputs, padding=\"longest\",return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic82I71QbTT_",
        "outputId": "08ff8840-b790-4fe9-af92-66a3dee433a0"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     1,  20967, 104917,  ...,    260,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,   1141,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,   1262,      2,      0],\n",
              "        ...,\n",
              "        [     1,  20967, 104917,  ...,    260,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,    260,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,    955,    260,      2]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUR3bRY8XPIt",
        "outputId": "4cdb880f-3f16-4269-f3f4-2c4e3806ccea"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.4895,  0.7833, -1.2925],\n",
              "        [ 0.4966,  0.7800, -1.2969],\n",
              "        [ 0.5023,  0.7791, -1.3011],\n",
              "        [ 0.4747,  0.7846, -1.2829],\n",
              "        [ 0.4605,  0.7860, -1.2724],\n",
              "        [ 0.4894,  0.7813, -1.2937],\n",
              "        [ 0.5049,  0.7781, -1.3043],\n",
              "        [ 0.4948,  0.7800, -1.2965],\n",
              "        [ 0.4925,  0.7803, -1.2950],\n",
              "        [ 0.4908,  0.7811, -1.2939]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_preds = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "sm_preds"
      ],
      "metadata": {
        "id": "U53zfdIULvwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dd38bac-9548-4b8b-97cb-0e7dbf30060b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3985, 0.5345, 0.0671],\n",
              "        [0.4010, 0.5323, 0.0667],\n",
              "        [0.4026, 0.5310, 0.0663],\n",
              "        [0.3944, 0.5376, 0.0680],\n",
              "        [0.3904, 0.5406, 0.0690],\n",
              "        [0.3989, 0.5341, 0.0671],\n",
              "        [0.4036, 0.5303, 0.0661],\n",
              "        [0.4005, 0.5327, 0.0668],\n",
              "        [0.3999, 0.5332, 0.0669],\n",
              "        [0.3993, 0.5337, 0.0670]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not iskaggle:\n",
        "    push_notebook('saan', comp,\n",
        "                  title='Feedback effeciveness: debertav3 - metrics fixed',\n",
        "                  file='/content/drive/MyDrive/Colab Notebooks/all_text_concat_DBERTA.ipynb',\n",
        "                  competition=comp, private=False, gpu=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-G7W9Szfhe8",
        "outputId": "379bd403-87b8-4788-c4b2-72545ce72416"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your kernel title does not resolve to the specified id. This may result in surprising behavior. We suggest making your title something that resolves to the specified id. See https://en.wikipedia.org/wiki/Clean_URL#Slug for more information on how slugs are determined.\n",
            "Kernel version 1 successfully pushed.  Please check progress at https://www.kaggle.com/code/saansd2003/feedback-effeciveness-debertav3-metrics-fixed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4D0dYKQ4cQk7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}