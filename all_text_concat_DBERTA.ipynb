{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_text_concat_DBERTA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBlUe96JwtTumflEDk+ZBq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c31d0d4b26f4bcc955bcf84eaf80fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fed82ddaa3ec415889c6515842be2caf",
              "IPY_MODEL_cafc9cde539e4fd68f48df404e792214",
              "IPY_MODEL_d0440e0e06d747d3a1f891145aec8fe6"
            ],
            "layout": "IPY_MODEL_bc852f240246464db785f63fe1c01fd0"
          }
        },
        "fed82ddaa3ec415889c6515842be2caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979c89bbd5a04d7f91cc749ca6f4c03a",
            "placeholder": "​",
            "style": "IPY_MODEL_955e9584855d42ecbf8f7cbbdb7ce654",
            "value": "100%"
          }
        },
        "cafc9cde539e4fd68f48df404e792214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3862a068cbd34e18b50a3e6b8d44acc2",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44ac64ecd2e14417a9f88b84e47ce0c4",
            "value": 37
          }
        },
        "d0440e0e06d747d3a1f891145aec8fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a4c166b384249269a897fd5c236040b",
            "placeholder": "​",
            "style": "IPY_MODEL_4eddcf1921634750a391f18faea870bd",
            "value": " 37/37 [01:03&lt;00:00,  1.85s/ba]"
          }
        },
        "bc852f240246464db785f63fe1c01fd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979c89bbd5a04d7f91cc749ca6f4c03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "955e9584855d42ecbf8f7cbbdb7ce654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3862a068cbd34e18b50a3e6b8d44acc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44ac64ecd2e14417a9f88b84e47ce0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a4c166b384249269a897fd5c236040b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eddcf1921634750a391f18faea870bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/feedback-prize-effectiveness/blob/main/all_text_concat_DBERTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vAwrF3S24Hzn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try: import fastkaggle\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -Uq fastkaggle\n",
        "\n",
        "!pip install -q datasets\n",
        "!pip install transformers\n",
        "!pip install sentencepiece \n",
        "!pip install pynvml\n",
        "from fastkaggle import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "CIpACVZUk0VM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "J0E4FZde4QB3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config depending on whether this is running on kaggle or collab\n",
        "# is_colab = True\n",
        "is_colab = not os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "comp = 'feedback-prize-effectiveness'\n",
        "if is_colab:\n",
        "    model_save_path = Path('/content/'+comp+'_out/models')\n",
        "else:\n",
        "    model_save_path = Path('/kaggle/working/'+comp) #+'/models')"
      ],
      "metadata": {
        "id": "LwaMmLpipyJd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import colab libraries\n",
        "if is_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOjHaaj64SAU",
        "outputId": "4d87f1e0-4926-4067-85d5-4cd17028ca5d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so lets move it there.\n",
        "if is_colab:\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/Kaggle_api_auth/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Rv1FT2oS4X_3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "if is_colab:\n",
        "    !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SM6uBIQ34eqk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = setup_comp(comp)\n",
        "path"
      ],
      "metadata": {
        "id": "Ikwoyt764icQ",
        "outputId": "f37acff5-631f-4b8a-e0c5-cebbfdd4ca40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading feedback-prize-effectiveness.zip to /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.13M/8.13M [00:00<00:00, 125MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('feedback-prize-effectiveness')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text classification"
      ],
      "metadata": {
        "id": "_WyXQ4ySSyUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def file_read(file_path):\n",
        "    with open(file_path, 'r') as _f: \n",
        "        all_content = _f.read()\n",
        "    return all_content"
      ],
      "metadata": {
        "id": "DaZzI-zTqNSx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process text - add all columns \n",
        "df = pd.read_csv(path/'train.csv')\n",
        "df['essay_text'] = df['essay_id'].apply(lambda x: file_read(path / 'train' / f'{x}.txt'))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XY6PVulLoZFY",
        "outputId": "447e0fba-d7a6-45b6-dd78-fffe02abc854"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   discourse_id      essay_id  \\\n",
              "0  0013cc385424  007ACE74B050   \n",
              "1  9704a709b505  007ACE74B050   \n",
              "2  c22adee811b6  007ACE74B050   \n",
              "3  a10d361e54e4  007ACE74B050   \n",
              "4  db3e453ec4e2  007ACE74B050   \n",
              "\n",
              "                                      discourse_text discourse_type  \\\n",
              "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
              "1  On my perspective, I think that the face is a ...       Position   \n",
              "2  I think that the face is a natural landform be...          Claim   \n",
              "3  If life was on Mars, we would know by now. The...       Evidence   \n",
              "4  People thought that the face was formed by ali...   Counterclaim   \n",
              "\n",
              "  discourse_effectiveness                                         essay_text  \n",
              "0                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "1                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "2                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "3                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "4                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ac6c763-d544-4163-afbf-0ddb2175c37a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>essay_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0013cc385424</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9704a709b505</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c22adee811b6</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a10d361e54e4</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>If life was on Mars, we would know by now. The...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>db3e453ec4e2</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>People thought that the face was formed by ali...</td>\n",
              "      <td>Counterclaim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ac6c763-d544-4163-afbf-0ddb2175c37a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ac6c763-d544-4163-afbf-0ddb2175c37a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ac6c763-d544-4163-afbf-0ddb2175c37a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See sequence length\n",
        "df['seq_length_essay'] = [len(txt.split()) for txt in df['essay_text'].tolist()]\n",
        "df['seq_length_dis'] = [len(txt.split()) for txt in df['discourse_text'].tolist()]\n",
        "df['seq_length_essay'].describe(), df['seq_length_dis'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__FA3GVwqeI",
        "outputId": "dea326f1-53d1-4b78-d541-78435763e266"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(count    36765.000000\n",
              " mean       458.588522\n",
              " std        220.423420\n",
              " min        144.000000\n",
              " 25%        288.000000\n",
              " 50%        408.000000\n",
              " 75%        579.000000\n",
              " max       1367.000000\n",
              " Name: seq_length_essay, dtype: float64, count    36765.000000\n",
              " mean        44.654073\n",
              " std         46.669682\n",
              " min          1.000000\n",
              " 25%         16.000000\n",
              " 50%         28.000000\n",
              " 75%         57.000000\n",
              " max        836.000000\n",
              " Name: seq_length_dis, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace discorse text within the context text as __MASKED__\n",
        "df['masked_ess_txt'] = df[['essay_text','discourse_text']].apply(lambda row: row.essay_text.strip().replace(row.discourse_text.strip(),\n",
        "                                                                                                         '__MASKED__'),\n",
        "                                                              axis = 1)\n",
        "df['seq_length_mask_ess'] = [len(txt.split()) for txt in df['masked_ess_txt'].tolist()]\n",
        "df['masked_ess_txt'].head(), df['seq_length_mask_ess'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSq5YwUFHsgH",
        "outputId": "868824cd-c22d-4607-9c24-779e21c6d074"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    __MASKED__ On my perspective, I think that the...\n",
              " 1    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 2    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 3    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 4    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " Name: masked_ess_txt, dtype: object, count    36765.000000\n",
              " mean       414.791024\n",
              " std        213.788307\n",
              " min          1.000000\n",
              " 25%        254.000000\n",
              " 50%        367.000000\n",
              " 75%        531.000000\n",
              " max       1345.000000\n",
              " Name: seq_length_mask_ess, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to truncate discourse text and context text\n",
        "# this is still in progress\n",
        "# def trunc_text(text, num_words, unique_centre_tok = None):\n",
        "#     w_l = text.split()\n",
        "#     if unique_centre_tok is None:\n",
        "#         if len(w_l) > num_words: w_l = w_l[:num_words]\n",
        "#     else:\n",
        "#         if len(w_l) > num_words:\n",
        "#             try: pos_tok = w_l.index(unique_centre_tok) + 1\n",
        "#             except: # in case there is an issue with the replacement\n",
        "#                 print(text)\n",
        "#                 pos_tok = round(num_words / 2)\n",
        "#             if pos_tok > round(len(w_l) / 2):\n",
        "#                 if len(w_l) > pos_tok + round((num_words - 1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words - 1) / 2) - 1\n",
        "#                 else:\n",
        "#                     start_pos = len(w_l) - num_words\n",
        "#                 w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#             else:\n",
        "#                 if pos_tok > round((num_words -1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words -1) / 2) - 1\n",
        "#                     w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#                 else:\n",
        "#                     w_l = w_l[:num_words]\n",
        "            \n",
        "#     return ' '.join(w_l)\n",
        "\n",
        "# [trunc_text(\"let's see where __MASKED__ we are going.\", i, unique_centre_tok = \"__MASKED__\") for i in range(2,8)]"
      ],
      "metadata": {
        "id": "VFLhCiRbrWKG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all text columns for classification \n",
        "# concat all\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text + '; DISCOURSE: ' + df.discourse_text + '; TYPE: ' + df.discourse_type\n",
        "\n",
        "# concat after truncation\n",
        "# df['essay_text_trunc'] = df.masked_ess_txt.apply(lambda t: trunc_text(t,512, \"__MASKED__\"))\n",
        "# df['discourse_text_trunc'] = df.discourse_text.apply(lambda t: trunc_text(t,64))\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text_trunc + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text_trunc \n",
        "df['input'] = 'CONTEXT: ' + df.masked_ess_txt + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text\n",
        "df['seq_length_input'] = [len(txt.split()) for txt in df['input'].tolist()]\n",
        "df['seq_length_input'].describe()"
      ],
      "metadata": {
        "id": "xy67RMN42OSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848413e3-5770-4eb8-9e39-5ec49ba54da6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    36765.000000\n",
              "mean       463.536244\n",
              "std        220.382475\n",
              "min        149.000000\n",
              "25%        293.000000\n",
              "50%        413.000000\n",
              "75%        584.000000\n",
              "max       1373.000000\n",
              "Name: seq_length_input, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create data datasets\n",
        "from datasets import Dataset,DatasetDict\n",
        "ds = Dataset.from_pandas(df)\n",
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpWa5edK5ac1",
        "outputId": "121e0248-183b-43ef-8bc9-99a4b7c99be5"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'all_text', 'seq_length_all', 'input', 'seq_length_input'],\n",
              "    num_rows: 36765\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "from datasets import ClassLabel\n",
        "labels = ClassLabel(names=df.discourse_effectiveness.unique().tolist())"
      ],
      "metadata": {
        "id": "DWXrIMfaE0xr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nm = 'microsoft/deberta-v3-small'"
      ],
      "metadata": {
        "id": "V2bnJl5Ie2KP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer, DataCollatorWithPadding\n",
        "tokz = AutoTokenizer.from_pretrained(model_nm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEDjRQnlhDqo",
        "outputId": "653ce3e9-e704-4724-c7b6-ed98fb967b84"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/spm.model from cache at /root/.cache/huggingface/transformers/3ed0740946d0a60434dd6a0c940068899c0b48bb5caba7d60c1db454877c64a3.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
            "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/b40830d1301d39fdc8c6a059787f7f46b8786c252b5475512aa5cf0a66020075.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
            "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "Adding [MASK] to the vocabulary\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.model_max_length, tokz.is_fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MESpUL477PV",
        "outputId": "b81ee4b3-6768-4112-d55a-8d00517f710c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000000000000000019884624838656, True)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tok_func(batch): \n",
        "    tokens = tokz(batch[\"input\"], padding=\"longest\") #, truncation=True)\n",
        "    tokens['labels'] = [float(l) for l in labels.str2int(batch['discourse_effectiveness'])]\n",
        "    return tokens\n",
        "tok_ds = ds.map(tok_func, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9c31d0d4b26f4bcc955bcf84eaf80fff",
            "fed82ddaa3ec415889c6515842be2caf",
            "cafc9cde539e4fd68f48df404e792214",
            "d0440e0e06d747d3a1f891145aec8fe6",
            "bc852f240246464db785f63fe1c01fd0",
            "979c89bbd5a04d7f91cc749ca6f4c03a",
            "955e9584855d42ecbf8f7cbbdb7ce654",
            "3862a068cbd34e18b50a3e6b8d44acc2",
            "44ac64ecd2e14417a9f88b84e47ce0c4",
            "8a4c166b384249269a897fd5c236040b",
            "4eddcf1921634750a391f18faea870bd"
          ]
        },
        "id": "tMGkk70YhHDk",
        "outputId": "1b43a477-6b53-4d12-d4f2-ced858358b03"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/37 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c31d0d4b26f4bcc955bcf84eaf80fff"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tok_ds = tok_ds.rename_columns({'discourse_effectiveness':'labels'})"
      ],
      "metadata": {
        "id": "Y7lT5AINvNLt"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# row = tok_ds[0]\n",
        "# row['input'], row['input_ids'], row['labels']"
      ],
      "metadata": {
        "id": "jJHfjPCq41Ov"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfoZ3OGIkut4",
        "outputId": "89986b3a-8989-41c9-f474-d4bae06e9fcc"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'all_text', 'seq_length_all', 'input', 'seq_length_input', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 27573\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'all_text', 'seq_length_all', 'input', 'seq_length_input', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 9192\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer\n"
      ],
      "metadata": {
        "id": "1yO1kdpelBcn"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokz)"
      ],
      "metadata": {
        "id": "ftOtAxTECx-1"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 4\n",
        "grad_acc = 16\n",
        "epochs = 4\n",
        "lr = 0.01\n",
        "\n",
        "args = TrainingArguments('outputs', learning_rate=lr,\n",
        "                         warmup_ratio=0.1,\n",
        "                         lr_scheduler_type='cosine',\n",
        "                         fp16=True,\n",
        "                        evaluation_strategy=\"epoch\",\n",
        "                         per_device_train_batch_size=bs,\n",
        "                          per_device_eval_batch_size=bs*2,\n",
        "                            num_train_epochs=epochs,\n",
        "                          weight_decay=0.01,\n",
        "                         gradient_accumulation_steps=grad_acc,\n",
        "                          report_to='none')"
      ],
      "metadata": {
        "id": "129jbaWJlJ2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1527e5d1-d807-4924-c149-669f69d52bee"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "def report_gpu():\n",
        "    print(torch.cuda.list_gpu_processes())\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "L6RYU1RW6O48"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35s9cdAO6Wvw",
        "outputId": "3824294a-d83a-40eb-eee8-6e872567232e"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU:0\n",
            "process       4105 uses    15545.000 MB GPU memory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
        "trainer = Trainer(model, args, \n",
        "                  train_dataset=dds['train'], \n",
        "                  eval_dataset=dds['test'],\n",
        "                  data_collator=data_collator,\n",
        "                  tokenizer=tokz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG50TpjnlZuj",
        "outputId": "c1e341e4-5783-4594-a1d7-b9b25ea00c4c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ce3185000148731a86ceaf533caa85fe513fc79e02b7fe5831fb1ed52a0e0d22.7e73b1561275ae3b633ba76ab7e4889d28d73dbcdc008cbc2414369b39da319b\n",
            "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "U_MEO-4gl1YP",
        "outputId": "139b7f00-da04-4164-a5f9-daf58b6a89af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: masked_ess_txt, discourse_text, discourse_effectiveness, discourse_type, seq_length_essay, all_text, seq_length_input, discourse_id, essay_id, seq_length_all, input, seq_length_dis, seq_length_mask_ess, essay_text. If masked_ess_txt, discourse_text, discourse_effectiveness, discourse_type, seq_length_essay, all_text, seq_length_input, discourse_id, essay_id, seq_length_all, input, seq_length_dis, seq_length_mask_ess, essay_text are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 27573\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 1720\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='1720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  32/1720 07:03 < 6:36:52, 0.07 it/s, Epoch 0.07/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPEQGpKBl_Fh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}