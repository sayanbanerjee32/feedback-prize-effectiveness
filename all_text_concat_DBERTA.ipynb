{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_text_concat_DBERTA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4iSI7E9vHJCg+TdtXT3db",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "411ff6d2dec640ccb9274498a8acce70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93a04c5457d54889a6e9d57097120247",
              "IPY_MODEL_6a7527c08f9d42ef88cc20b504030dcc",
              "IPY_MODEL_c586a038f85a41678d0b8a7cec3fd83a"
            ],
            "layout": "IPY_MODEL_7245a89f309b4fb1a2f79c7dad6766e4"
          }
        },
        "93a04c5457d54889a6e9d57097120247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72d8370514c74229965a8dbfa6b7b6f8",
            "placeholder": "​",
            "style": "IPY_MODEL_0801a8641ed647c5882349e59dd79939",
            "value": "100%"
          }
        },
        "6a7527c08f9d42ef88cc20b504030dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23a0639f86d44c15b9bf22996673933a",
            "max": 37,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19d0d23c91574925a2a40cc3654ef65e",
            "value": 37
          }
        },
        "c586a038f85a41678d0b8a7cec3fd83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba3c5dc062c04ccf9efa260b222e430c",
            "placeholder": "​",
            "style": "IPY_MODEL_59a570ffdf0740e7ad82965952b19986",
            "value": " 37/37 [01:02&lt;00:00,  2.22s/ba]"
          }
        },
        "7245a89f309b4fb1a2f79c7dad6766e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72d8370514c74229965a8dbfa6b7b6f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0801a8641ed647c5882349e59dd79939": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23a0639f86d44c15b9bf22996673933a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19d0d23c91574925a2a40cc3654ef65e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba3c5dc062c04ccf9efa260b222e430c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59a570ffdf0740e7ad82965952b19986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f854f1b1b564d959b9b775f81a9a76e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81b298fe57a04b90bd04d454066fe27f",
              "IPY_MODEL_90608ca6914343af8367957a3be9a617",
              "IPY_MODEL_23c44d8a2e4a464d85320a33445cab60"
            ],
            "layout": "IPY_MODEL_197c83b774e6488894eedb78c5c981bc"
          }
        },
        "81b298fe57a04b90bd04d454066fe27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2a270a26e494ab3b129c7c55047179e",
            "placeholder": "​",
            "style": "IPY_MODEL_1b4a1379f56c4ef19a151b13a67be9a9",
            "value": "100%"
          }
        },
        "90608ca6914343af8367957a3be9a617": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f4979237ad488d975bac9b478f1b4b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c93fa0a3ed14300853220392ac69f30",
            "value": 1
          }
        },
        "23c44d8a2e4a464d85320a33445cab60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_942cef670c2240b0a40a71fa29d6335e",
            "placeholder": "​",
            "style": "IPY_MODEL_8b5e2ea0dc784d8990188895e102afd7",
            "value": " 1/1 [00:00&lt;00:00, 16.25ba/s]"
          }
        },
        "197c83b774e6488894eedb78c5c981bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2a270a26e494ab3b129c7c55047179e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b4a1379f56c4ef19a151b13a67be9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f4979237ad488d975bac9b478f1b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c93fa0a3ed14300853220392ac69f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "942cef670c2240b0a40a71fa29d6335e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b5e2ea0dc784d8990188895e102afd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/feedback-prize-effectiveness/blob/main/all_text_concat_DBERTA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vAwrF3S24Hzn"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try: import fastkaggle\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -Uq fastkaggle\n",
        "\n",
        "!pip install -q datasets\n",
        "!pip install transformers\n",
        "!pip install sentencepiece \n",
        "!pip install pynvml\n",
        "!pip install evaluate\n",
        "from fastkaggle import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "J0E4FZde4QB3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config depending on whether this is running on kaggle or collab\n",
        "# is_colab = True\n",
        "is_colab = not os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "comp = 'feedback-prize-effectiveness'\n",
        "if is_colab:\n",
        "    model_save_path = Path('/content/'+comp+'_out/models')\n",
        "else:\n",
        "    model_save_path = Path('/kaggle/working/'+comp) #+'/models')"
      ],
      "metadata": {
        "id": "LwaMmLpipyJd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if is_colab:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "CIpACVZUk0VM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import colab libraries\n",
        "if is_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UOjHaaj64SAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5bde829-2216-4f31-c0a8-52523f0ab2b3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so lets move it there.\n",
        "if is_colab:\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/Kaggle_api_auth/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Rv1FT2oS4X_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcc13d2-9537-4722-eb53-cf41e71798ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "if is_colab:\n",
        "    !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SM6uBIQ34eqk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = setup_comp(comp)\n",
        "path"
      ],
      "metadata": {
        "id": "Ikwoyt764icQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632e4f40-7b0c-411d-b979-5c5fce2cae0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('feedback-prize-effectiveness')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text classification"
      ],
      "metadata": {
        "id": "_WyXQ4ySSyUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def file_read(file_path):\n",
        "    with open(file_path, 'r') as _f: \n",
        "        all_content = _f.read()\n",
        "    return all_content"
      ],
      "metadata": {
        "id": "DaZzI-zTqNSx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process text - add all columns \n",
        "df = pd.read_csv(path/'train.csv')\n",
        "df['essay_text'] = df['essay_id'].apply(lambda x: file_read(path / 'train' / f'{x}.txt'))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XY6PVulLoZFY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "outputId": "1039f986-90ea-4efa-98b2-a595c7514f29"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   discourse_id      essay_id  \\\n",
              "0  0013cc385424  007ACE74B050   \n",
              "1  9704a709b505  007ACE74B050   \n",
              "2  c22adee811b6  007ACE74B050   \n",
              "3  a10d361e54e4  007ACE74B050   \n",
              "4  db3e453ec4e2  007ACE74B050   \n",
              "\n",
              "                                      discourse_text discourse_type  \\\n",
              "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
              "1  On my perspective, I think that the face is a ...       Position   \n",
              "2  I think that the face is a natural landform be...          Claim   \n",
              "3  If life was on Mars, we would know by now. The...       Evidence   \n",
              "4  People thought that the face was formed by ali...   Counterclaim   \n",
              "\n",
              "  discourse_effectiveness                                         essay_text  \n",
              "0                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "1                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "2                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "3                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  \n",
              "4                Adequate  Hi, i'm Isaac, i'm going to be writing about h...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60d132ea-c628-46cd-8eb4-eceaf112dc1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>essay_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0013cc385424</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9704a709b505</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>On my perspective, I think that the face is a ...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c22adee811b6</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>I think that the face is a natural landform be...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a10d361e54e4</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>If life was on Mars, we would know by now. The...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>db3e453ec4e2</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>People thought that the face was formed by ali...</td>\n",
              "      <td>Counterclaim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60d132ea-c628-46cd-8eb4-eceaf112dc1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60d132ea-c628-46cd-8eb4-eceaf112dc1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60d132ea-c628-46cd-8eb4-eceaf112dc1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See sequence length\n",
        "df['seq_length_essay'] = [len(txt.split()) for txt in df['essay_text'].tolist()]\n",
        "df['seq_length_dis'] = [len(txt.split()) for txt in df['discourse_text'].tolist()]\n",
        "df['seq_length_essay'].describe(), df['seq_length_dis'].describe()"
      ],
      "metadata": {
        "id": "k__FA3GVwqeI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40218f2-862f-4871-d996-498ff7ba56b3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(count    36765.000000\n",
              " mean       458.588522\n",
              " std        220.423420\n",
              " min        144.000000\n",
              " 25%        288.000000\n",
              " 50%        408.000000\n",
              " 75%        579.000000\n",
              " max       1367.000000\n",
              " Name: seq_length_essay, dtype: float64, count    36765.000000\n",
              " mean        44.654073\n",
              " std         46.669682\n",
              " min          1.000000\n",
              " 25%         16.000000\n",
              " 50%         28.000000\n",
              " 75%         57.000000\n",
              " max        836.000000\n",
              " Name: seq_length_dis, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace discorse text within the context text as __MASKED__\n",
        "df['masked_ess_txt'] = df[['essay_text','discourse_text']].apply(lambda row: row.essay_text.strip().replace(row.discourse_text.strip(),\n",
        "                                                                                                         '__MASKED__'),\n",
        "                                                              axis = 1)\n",
        "df['seq_length_mask_ess'] = [len(txt.split()) for txt in df['masked_ess_txt'].tolist()]\n",
        "df['masked_ess_txt'].head(), df['seq_length_mask_ess'].describe()"
      ],
      "metadata": {
        "id": "ZSq5YwUFHsgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f755f29f-b574-480a-b78f-9afe853c39d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    __MASKED__ On my perspective, I think that the...\n",
              " 1    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 2    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 3    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " 4    Hi, i'm Isaac, i'm going to be writing about h...\n",
              " Name: masked_ess_txt, dtype: object, count    36765.000000\n",
              " mean       414.791024\n",
              " std        213.788307\n",
              " min          1.000000\n",
              " 25%        254.000000\n",
              " 50%        367.000000\n",
              " 75%        531.000000\n",
              " max       1345.000000\n",
              " Name: seq_length_mask_ess, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to truncate discourse text and context text\n",
        "# this is still in progress\n",
        "# def trunc_text(text, num_words, unique_centre_tok = None):\n",
        "#     w_l = text.split()\n",
        "#     if unique_centre_tok is None:\n",
        "#         if len(w_l) > num_words: w_l = w_l[:num_words]\n",
        "#     else:\n",
        "#         if len(w_l) > num_words:\n",
        "#             try: pos_tok = w_l.index(unique_centre_tok) + 1\n",
        "#             except: # in case there is an issue with the replacement\n",
        "#                 print(text)\n",
        "#                 pos_tok = round(num_words / 2)\n",
        "#             if pos_tok > round(len(w_l) / 2):\n",
        "#                 if len(w_l) > pos_tok + round((num_words - 1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words - 1) / 2) - 1\n",
        "#                 else:\n",
        "#                     start_pos = len(w_l) - num_words\n",
        "#                 w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#             else:\n",
        "#                 if pos_tok > round((num_words -1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words -1) / 2) - 1\n",
        "#                     w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#                 else:\n",
        "#                     w_l = w_l[:num_words]\n",
        "            \n",
        "#     return ' '.join(w_l)\n",
        "\n",
        "# [trunc_text(\"let's see where __MASKED__ we are going.\", i, unique_centre_tok = \"__MASKED__\") for i in range(2,8)]"
      ],
      "metadata": {
        "id": "VFLhCiRbrWKG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all text columns for classification \n",
        "# concat all\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text + '; DISCOURSE: ' + df.discourse_text + '; TYPE: ' + df.discourse_type\n",
        "\n",
        "# concat after truncation\n",
        "# df['essay_text_trunc'] = df.masked_ess_txt.apply(lambda t: trunc_text(t,512, \"__MASKED__\"))\n",
        "# df['discourse_text_trunc'] = df.discourse_text.apply(lambda t: trunc_text(t,64))\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text_trunc + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text_trunc \n",
        "df['input'] = 'CONTEXT: ' + df.masked_ess_txt + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text\n",
        "df['seq_length_input'] = [len(txt.split()) for txt in df['input'].tolist()]\n",
        "df['seq_length_input'].describe()"
      ],
      "metadata": {
        "id": "xy67RMN42OSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277e8ef9-1a10-40b7-fa28-c35f8292088d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    36765.000000\n",
              "mean       463.536244\n",
              "std        220.382475\n",
              "min        149.000000\n",
              "25%        293.000000\n",
              "50%        413.000000\n",
              "75%        584.000000\n",
              "max       1373.000000\n",
              "Name: seq_length_input, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# random sampling to test in collab\n",
        "# if is_colab: df = df.sample(frac=0.10)\n",
        "df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVB7CqH6HVe3",
        "outputId": "6a5154d4-a5dc-4584-fcdf-9e63dad4698c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36765"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create data datasets\n",
        "from datasets import Dataset,DatasetDict\n",
        "ds = Dataset.from_pandas(df)\n",
        "ds"
      ],
      "metadata": {
        "id": "SpWa5edK5ac1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30132aa-9ebf-46fe-80d0-9c3d7864c850"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'input', 'seq_length_input'],\n",
              "    num_rows: 36765\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encoding\n",
        "from datasets import ClassLabel\n",
        "labels = ClassLabel(names=df.discourse_effectiveness.unique().tolist())"
      ],
      "metadata": {
        "id": "DWXrIMfaE0xr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_nm = 'microsoft/deberta-v3-small'"
      ],
      "metadata": {
        "id": "V2bnJl5Ie2KP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer, DataCollatorWithPadding\n",
        "tokz = AutoTokenizer.from_pretrained(model_nm)"
      ],
      "metadata": {
        "id": "pEDjRQnlhDqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "522de3d6-8aca-4ac4-bfca-9f48857d2c65"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokz.model_max_length, tokz.is_fast"
      ],
      "metadata": {
        "id": "6MESpUL477PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e56f78-69c8-4ea7-9926-b27ec0109ee4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000000000000000019884624838656, True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tok_func(batch, is_test = False): \n",
        "    tokens = tokz(batch[\"input\"], padding=\"longest\") #, truncation=True)\n",
        "    if not is_test:\n",
        "        tokens['labels'] = [float(l) for l in labels.str2int(batch['discourse_effectiveness'])]\n",
        "    return tokens\n",
        "tok_ds = ds.map(tok_func, batched=True)"
      ],
      "metadata": {
        "id": "tMGkk70YhHDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "411ff6d2dec640ccb9274498a8acce70",
            "93a04c5457d54889a6e9d57097120247",
            "6a7527c08f9d42ef88cc20b504030dcc",
            "c586a038f85a41678d0b8a7cec3fd83a",
            "7245a89f309b4fb1a2f79c7dad6766e4",
            "72d8370514c74229965a8dbfa6b7b6f8",
            "0801a8641ed647c5882349e59dd79939",
            "23a0639f86d44c15b9bf22996673933a",
            "19d0d23c91574925a2a40cc3654ef65e",
            "ba3c5dc062c04ccf9efa260b222e430c",
            "59a570ffdf0740e7ad82965952b19986"
          ]
        },
        "outputId": "6f8b9465-b2ac-42db-adcd-2cdfeade0d35"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/37 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "411ff6d2dec640ccb9274498a8acce70"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.num_classes, labels.names"
      ],
      "metadata": {
        "id": "P0dx_ObXYEQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e93a608-ff5c-4ea5-dfae-6c10e89e1cba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, ['Adequate', 'Ineffective', 'Effective'])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tok_ds = tok_ds.rename_columns({'discourse_effectiveness':'labels'})"
      ],
      "metadata": {
        "id": "Y7lT5AINvNLt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# row = tok_ds[0]\n",
        "# row['input'], row['input_ids'], row['labels']"
      ],
      "metadata": {
        "id": "jJHfjPCq41Ov"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ],
      "metadata": {
        "id": "dfoZ3OGIkut4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18dc18e5-8ebb-4e7b-88b1-f13f09ff7e06"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'input', 'seq_length_input', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 27573\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'essay_text', 'seq_length_essay', 'seq_length_dis', 'masked_ess_txt', 'seq_length_mask_ess', 'input', 'seq_length_input', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 9192\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "import evaluate\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1yO1kdpelBcn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer=tokz)"
      ],
      "metadata": {
        "id": "ftOtAxTECx-1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 4\n",
        "grad_acc = 16\n",
        "epochs = 2\n",
        "lr = 2e-5\n",
        "metric_name = \"f1\"\n",
        "\n",
        "args = TrainingArguments('outputs', learning_rate=lr,\n",
        "                         warmup_ratio=0.1,\n",
        "                         lr_scheduler_type='cosine',\n",
        "                         fp16=True,\n",
        "                        evaluation_strategy=\"epoch\",\n",
        "                         logging_strategy = \"epoch\",\n",
        "                         per_device_train_batch_size=bs,\n",
        "                          per_device_eval_batch_size=bs*2,\n",
        "                        num_train_epochs=epochs,\n",
        "                          weight_decay=0.01,\n",
        "                         gradient_accumulation_steps=grad_acc,\n",
        "                        #   load_best_model_at_end=True,\n",
        "                            metric_for_best_model=metric_name,\n",
        "                         label_names = labels.names,\n",
        "                          report_to='none')"
      ],
      "metadata": {
        "id": "129jbaWJlJ2H"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "def report_gpu():\n",
        "    print(torch.cuda.list_gpu_processes())\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "L6RYU1RW6O48"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report_gpu()"
      ],
      "metadata": {
        "id": "35s9cdAO6Wvw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a0910a-c163-4a97-c251-0fa35298520f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU:0\n",
            "no processes are running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_nm, \n",
        "                                                           num_labels=labels.num_classes)\n",
        "def compute_metrics(eval_preds):\n",
        "    metric = evaluate.load(\"f1\")\n",
        "    metric = evaluate.load(\"accuracy\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(model, args, \n",
        "                  train_dataset=dds['train'], \n",
        "                  eval_dataset=dds['test'],\n",
        "                  data_collator=data_collator,\n",
        "                  tokenizer=tokz,\n",
        "                  compute_metrics=compute_metrics)"
      ],
      "metadata": {
        "id": "yG50TpjnlZuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c8b6f3-ecd4-4a2c-f34f-0abd8c7bcaf9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.bias']\n",
            "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using cuda_amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train();"
      ],
      "metadata": {
        "id": "U_MEO-4gl1YP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "9dd2da52-49d0-4853-f6a3-ddea4072ded6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: discourse_type, essay_text, discourse_id, essay_id, discourse_text, seq_length_essay, masked_ess_txt, seq_length_input, discourse_effectiveness, seq_length_mask_ess, seq_length_dis, input. If discourse_type, essay_text, discourse_id, essay_id, discourse_text, seq_length_essay, masked_ess_txt, seq_length_input, discourse_effectiveness, seq_length_mask_ess, seq_length_dis, input are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 27573\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 16\n",
            "  Total optimization steps = 860\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='861' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [860/860 3:34:44, Epoch 2.00/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1070' max='1149' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1070/1149 11:37 < 00:51, 1.53 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: discourse_type, essay_text, discourse_id, essay_id, discourse_text, seq_length_essay, masked_ess_txt, seq_length_input, discourse_effectiveness, seq_length_mask_ess, seq_length_dis, input. If discourse_type, essay_text, discourse_id, essay_id, discourse_text, seq_length_essay, masked_ess_txt, seq_length_input, discourse_effectiveness, seq_length_mask_ess, seq_length_dis, input are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9192\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to outputs/checkpoint-500\n",
            "Configuration saved in outputs/checkpoint-500/config.json\n",
            "Model weights saved in outputs/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in outputs/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in outputs/checkpoint-500/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: discourse_type, essay_text, discourse_id, essay_id, discourse_text, seq_length_essay, masked_ess_txt, seq_length_input, discourse_effectiveness, seq_length_mask_ess, seq_length_dis, input. If discourse_type, essay_text, discourse_id, essay_id, discourse_text, seq_length_essay, masked_ess_txt, seq_length_input, discourse_effectiveness, seq_length_mask_ess, seq_length_dis, input are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 9192\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='860' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [860/860 3:47:13, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.758300</td>\n",
              "      <td>No log</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2Y2OXrMe3aZ",
        "outputId": "df912a80-7696-4576-d29c-38d0c6e01c7d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/feedback-prize-effectiveness_out/models\n",
            "Configuration saved in /content/feedback-prize-effectiveness_out/models/config.json\n",
            "Model weights saved in /content/feedback-prize-effectiveness_out/models/pytorch_model.bin\n",
            "tokenizer config file saved in /content/feedback-prize-effectiveness_out/models/tokenizer_config.json\n",
            "Special tokens file saved in /content/feedback-prize-effectiveness_out/models/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test prediction"
      ],
      "metadata": {
        "id": "sY9r7pEQI_na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_df = pd.read_csv(path/'test.csv')\n",
        "# pre-process test df texts\n",
        "eval_df['essay_text'] = eval_df['essay_id'].apply(lambda x: file_read(path / 'test' / f'{x}.txt'))\n",
        "eval_df['masked_ess_txt'] = eval_df[['essay_text','discourse_text']].apply(lambda row: row.essay_text.strip().replace(row.discourse_text.strip(),\n",
        "                                                                                                         '__MASKED__'),\n",
        "                                                              axis = 1)\n",
        "eval_df['input'] = 'CONTEXT: ' + eval_df.masked_ess_txt + '; TYPE: ' + eval_df.discourse_type + '; DISCOURSE: ' + eval_df.discourse_text"
      ],
      "metadata": {
        "id": "66ZCDjawJPyp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "tst_tok_func = partial(tok_func, is_test = True)\n",
        "eval_ds = Dataset.from_pandas(eval_df).map(tst_tok_func, batched=True)"
      ],
      "metadata": {
        "id": "X-UY7SRFJFfB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8f854f1b1b564d959b9b775f81a9a76e",
            "81b298fe57a04b90bd04d454066fe27f",
            "90608ca6914343af8367957a3be9a617",
            "23c44d8a2e4a464d85320a33445cab60",
            "197c83b774e6488894eedb78c5c981bc",
            "c2a270a26e494ab3b129c7c55047179e",
            "1b4a1379f56c4ef19a151b13a67be9a9",
            "f9f4979237ad488d975bac9b478f1b4b",
            "4c93fa0a3ed14300853220392ac69f30",
            "942cef670c2240b0a40a71fa29d6335e",
            "8b5e2ea0dc784d8990188895e102afd7"
          ]
        },
        "outputId": "44d71d27-8821-41d9-e5f2-350e21fab7f6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f854f1b1b564d959b9b775f81a9a76e"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/d2e234f7cc04bf79/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = trainer.predict(eval_ds).predictions\n",
        "preds.astype(float)"
      ],
      "metadata": {
        "id": "EPEQGpKBl_Fh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "64e7924b-e242-4fca-bab6-aa09d91c1737"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: discourse_type, essay_text, discourse_id, essay_id, discourse_text, masked_ess_txt, input. If discourse_type, essay_text, discourse_id, essay_id, discourse_text, masked_ess_txt, input are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running Prediction *****\n",
            "  Num examples = 10\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.50683594, -0.71386719, -0.49707031],\n",
              "       [ 1.41796875, -0.82470703, -0.36181641],\n",
              "       [ 1.33886719, -0.97070312, -0.11932373],\n",
              "       [ 1.37109375, -0.90087891, -0.23364258],\n",
              "       [ 1.36035156, -0.94628906, -0.17431641],\n",
              "       [ 1.75097656,  0.16772461, -1.60742188],\n",
              "       [ 1.76953125,  0.16845703, -1.61816406],\n",
              "       [ 1.37011719, -0.90332031, -0.22814941],\n",
              "       [ 1.74023438,  0.1394043 , -1.57421875],\n",
              "       [ 1.60351562, -0.24938965, -1.08300781]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LycepdfuZYj7",
        "outputId": "32d76585-f4f6-4b02-a076-72b37be4fdf8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/feedback-prize-effectiveness_out/models/config.json\n",
            "Model config DebertaV2Config {\n",
            "  \"_name_or_path\": \"/content/feedback-prize-effectiveness_out/models\",\n",
            "  \"architectures\": [\n",
            "    \"DebertaV2ForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-07,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_relative_positions\": -1,\n",
            "  \"model_type\": \"deberta-v2\",\n",
            "  \"norm_rel_ebd\": \"layer_norm\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_dropout\": 0,\n",
            "  \"pooler_hidden_act\": \"gelu\",\n",
            "  \"pooler_hidden_size\": 768,\n",
            "  \"pos_att_type\": [\n",
            "    \"p2c\",\n",
            "    \"c2p\"\n",
            "  ],\n",
            "  \"position_biased_input\": false,\n",
            "  \"position_buckets\": 256,\n",
            "  \"relative_attention\": true,\n",
            "  \"share_att_key\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"type_vocab_size\": 0,\n",
            "  \"vocab_size\": 128100\n",
            "}\n",
            "\n",
            "loading weights file /content/feedback-prize-effectiveness_out/models/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
            "\n",
            "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /content/feedback-prize-effectiveness_out/models.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_inputs = eval_df['input'].tolist()\n",
        "inputs = tokz(raw_inputs, padding=\"longest\",return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ic82I71QbTT_",
        "outputId": "a444a180-ee36-48b3-b501-2b88092aba40"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[     1,  20967, 104917,  ...,    260,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,   1141,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,   1262,      2,      0],\n",
              "        ...,\n",
              "        [     1,  20967, 104917,  ...,    260,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,    260,      2,      0],\n",
              "        [     1,  20967, 104917,  ...,    955,    260,      2]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0],\n",
              "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 0],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(**inputs)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUR3bRY8XPIt",
        "outputId": "93f83181-b822-4dd6-cb6d-f19687ae65ad"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.5059, -0.7145, -0.4957],\n",
              "        [ 1.4183, -0.8250, -0.3606],\n",
              "        [ 1.3389, -0.9720, -0.1175],\n",
              "        [ 1.3704, -0.9007, -0.2334],\n",
              "        [ 1.3602, -0.9467, -0.1738],\n",
              "        [ 1.7512,  0.1669, -1.6067],\n",
              "        [ 1.7691,  0.1683, -1.6178],\n",
              "        [ 1.3703, -0.9031, -0.2276],\n",
              "        [ 1.7407,  0.1385, -1.5733],\n",
              "        [ 1.6038, -0.2496, -1.0825]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sm_preds = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "sm_preds"
      ],
      "metadata": {
        "id": "U53zfdIULvwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b567663d-5fb7-4ef4-bee8-6e0c7a64b567"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8041, 0.0873, 0.1086],\n",
              "        [0.7844, 0.0832, 0.1324],\n",
              "        [0.7506, 0.0744, 0.1749],\n",
              "        [0.7667, 0.0791, 0.1542],\n",
              "        [0.7603, 0.0757, 0.1640],\n",
              "        [0.8065, 0.1654, 0.0281],\n",
              "        [0.8094, 0.1633, 0.0274],\n",
              "        [0.7661, 0.0789, 0.1550],\n",
              "        [0.8079, 0.1627, 0.0294],\n",
              "        [0.8164, 0.1279, 0.0556]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not iskaggle:\n",
        "    push_notebook('saan', comp,\n",
        "                  title='Feedback effeciveness: debertav3 small',\n",
        "                  file='/content/drive/MyDrive/Colab Notebooks/all_text_concat_DBERTA.ipynb',\n",
        "                  competition=comp, private=False, gpu=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "z-G7W9Szfhe8",
        "outputId": "e78c8363-b332-4f2c-8cbf-b849389fe8be"
      },
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your kernel title does not resolve to the specified id. This may result in surprising behavior. We suggest making your title something that resolves to the specified id. See https://en.wikipedia.org/wiki/Clean_URL#Slug for more information on how slugs are determined.\n"
          ]
        },
        {
          "ename": "ApiException",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mApiException\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-bab2b18989f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Feedback effeciveness: debertav3 small'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/all_text_concat_DBERTA.ipynb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                   competition=comp, private=False, gpu=True)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/fastkaggle/core.py\u001b[0m in \u001b[0;36mpush_notebook\u001b[0;34m(user, id, title, file, path, competition, private, gpu, internet)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_kaggle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels_push_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# %% ../00_core.ipynb 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mkernels_push_cli\u001b[0;34m(self, folder)\u001b[0m\n\u001b[1;32m   1905\u001b[0m         \"\"\"\n\u001b[1;32m   1906\u001b[0m         \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1907\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernels_push\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api_extended.py\u001b[0m in \u001b[0;36mkernels_push\u001b[0;34m(self, folder)\u001b[0m\n\u001b[1;32m   1898\u001b[0m             self.process_response(\n\u001b[1;32m   1899\u001b[0m                 self.kernel_push_with_http_info(\n\u001b[0;32m-> 1900\u001b[0;31m                     kernel_push_request=kernel_push_request)))\n\u001b[0m\u001b[1;32m   1901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/api/kaggle_api.py\u001b[0m in \u001b[0;36mkernel_push_with_http_info\u001b[0;34m(self, kernel_push_request, **kwargs)\u001b[0m\n\u001b[1;32m   2435\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_preload_content'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2436\u001b[0m             \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_request_timeout'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2437\u001b[0;31m             collection_formats=collection_formats)\n\u001b[0m\u001b[1;32m   2438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkernel_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_slug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: E501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/api_client.py\u001b[0m in \u001b[0;36mcall_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    332\u001b[0m                                    \u001b[0mresponse_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                                    \u001b[0m_return_http_data_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_formats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                                    _preload_content, _request_timeout)\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             thread = self.pool.apply_async(self.__call_api, (resource_path,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/api_client.py\u001b[0m in \u001b[0;36m__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mpost_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             _request_timeout=_request_timeout)\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/api_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    375\u001b[0m                                          \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                                          \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                                          body=body)\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PUT\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             return self.rest_client.PUT(url,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/rest.py\u001b[0m in \u001b[0;36mPOST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    286\u001b[0m                             \u001b[0m_preload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_preload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                             \u001b[0m_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                             body=body)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     def PUT(self, url, headers=None, query_params=None, post_params=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kaggle/rest.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m299\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_resp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mApiException\u001b[0m: (409)\nReason: Conflict\nHTTP response headers: HTTPHeaderDict({'Content-Type': 'application/json', 'Date': 'Sun, 28 Aug 2022 14:44:48 GMT', 'Access-Control-Allow-Credentials': 'true', 'Set-Cookie': 'ka_sessionid=55be0137655a063a061fbb05ba21bbec; max-age=2626560; path=/, GCLB=CPT9u6Hl6KHIxQE; path=/; HttpOnly', 'Transfer-Encoding': 'chunked', 'Vary': 'Accept-Encoding', 'Turbolinks-Location': 'https://www.kaggle.com/api/v1/kernels/push', 'X-Kaggle-MillisecondsElapsed': '172', 'X-Kaggle-RequestId': 'e78cf009fa0d724ee1d2d71721e46be8', 'X-Kaggle-ApiVersion': '1.5.12', 'X-Frame-Options': 'SAMEORIGIN', 'Strict-Transport-Security': 'max-age=63072000; includeSubDomains; preload', 'Content-Security-Policy': \"object-src 'none'; script-src 'nonce-PJ9UH+DyTgy/guPzFWGlVg==' 'report-sample' 'unsafe-inline' 'unsafe-eval' 'strict-dynamic' https: http:; frame-src 'self' https://www.kaggleusercontent.com https://www.youtube.com/embed/ https://polygraph-cool.github.io https://www.google.com/recaptcha/ https://form.jotform.com https://submit.jotform.us https://submit.jotformpro.com https://submit.jotform.com https://www.docdroid.com https://www.docdroid.net https://kaggle-static.storage.googleapis.com https://kaggle-static-staging.storage.googleapis.com https://kkb-dev.jupyter-proxy.kaggle.net https://kkb-staging.jupyter-proxy.kaggle.net https://kkb-production.jupyter-proxy.kaggle.net https://kkb-dev.firebaseapp.com https://kkb-staging.firebaseapp.com https://kkb-production.firebaseapp.com https://kaggle-metastore-test.firebaseapp.com https://kaggle-metastore.firebaseapp.com https://apis.google.com https://content-sheets.googleapis.com/ https://accounts.google.com/ https://storage.googleapis.com https://docs.google.com https://drive.google.com https://calendar.google.com/; base-uri 'none'; report-uri https://csp.withgoogle.com/csp/kaggle/20201130;\", 'X-Content-Type-Options': 'nosniff', 'Referrer-Policy': 'strict-origin-when-cross-origin', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"code\":409,\"message\":\"The requested title \\u0022Feedback effeciveness: debertav3 small\\u0022 is already in use by a kernel. Please choose another title.\"}\n"
          ]
        }
      ]
    }
  ]
}