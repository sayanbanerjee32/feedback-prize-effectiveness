{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "all_text_concat_ulmfit_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJcnm758AZ7QWCmSgpsct7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/feedback-prize-effectiveness/blob/main/all_text_concat_ulmfit_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAwrF3S24Hzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c9fc93-9616-49a0-d81b-614d55f06ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████                         | 10 kB 30.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 20 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 30 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 40 kB 3.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 46 kB 2.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# install fastkaggle if not available\n",
        "!pip install -Uq fastai\n",
        "try: import fastkaggle\n",
        "except ModuleNotFoundError:\n",
        "    !pip install -Uq fastkaggle\n",
        "\n",
        "# !pip install -Uq 'timm>=0.6.2.dev'\n",
        "!pip install -Uq pynvml\n",
        "from fastkaggle import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import fastai\n",
        "fastai.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "J0E4FZde4QB3",
        "outputId": "ce979892-d4b8-42e0-9560-7ccfa108d8b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.7.9'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config depending on whether this is running on kaggle or collab\n",
        "# is_colab = True\n",
        "is_colab = not os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
        "comp = 'feedback-prize-effectiveness'\n",
        "if is_colab:\n",
        "    model_save_path = Path('/content/'+comp+'_out/models')\n",
        "else:\n",
        "    model_save_path = Path('/kaggle/working/'+comp) #+'/models')"
      ],
      "metadata": {
        "id": "LwaMmLpipyJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import colab libraries\n",
        "if is_colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOjHaaj64SAU",
        "outputId": "c78b62a1-87ab-4823-c261-9d7b52930d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so lets move it there.\n",
        "if is_colab:\n",
        "    !mkdir ~/.kaggle\n",
        "    !cp /content/drive/MyDrive/Kaggle_api_auth/kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "Rv1FT2oS4X_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed0d1f1-5dda-4ef0-b6ff-c5223423bad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "if is_colab:\n",
        "    !chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "SM6uBIQ34eqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = setup_comp(comp)\n",
        "path"
      ],
      "metadata": {
        "id": "Ikwoyt764icQ",
        "outputId": "68000776-c2e0-4469-a145-777bfdea3f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading feedback-prize-effectiveness.zip to /content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.13M/8.13M [00:00<00:00, 244MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Path('feedback-prize-effectiveness')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.text.all import *\n",
        "set_seed(32)"
      ],
      "metadata": {
        "id": "Xihu0wcU4sSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Language model for original text"
      ],
      "metadata": {
        "id": "zigZQFGkStlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this cell fastai TextDataLoader functions are overridden to allow taking output \n",
        "# directory as input so that the toknised data is not written in data input directory\n",
        "# in Kaggle, data input directory is read-only\n",
        "from fastai.text.core import _tokenize_files\n",
        "@delegates(_tokenize_files)\n",
        "def tokenize_folderOP(path, extensions=None, folders=None,\n",
        "                      output_dir=None, skip_if_exists=True, **kwargs):\n",
        "    \"\"\"replacement of fastai.text.core.tokenize_folder so that it passes\n",
        "     output_dir as input to _tokenize_files\"\"\"\n",
        "    path,extensions = Path(path),ifnone(extensions, ['.txt'])\n",
        "    files = get_files(path, extensions=extensions, recurse=True, folders=folders)\n",
        "    def _f(i,output_dir): return output_dir/files[i].relative_to(path)\n",
        "    return _tokenize_files(_f, files, path, output_dir, \n",
        "                           skip_if_exists=skip_if_exists, **kwargs)\n",
        "\n",
        "class TokenizerOP(Tokenizer):\n",
        "    \"\"\"Wrapper class for fastai.text.core.Tokenizer class to override\n",
        "    from_folder method to take output_dir as input and call the overridden\n",
        "    method tokenize_folderOP\"\"\"\n",
        "    def __init__(self, tok, rules=None, counter=None,\n",
        "                 lengths=None, mode=None, sep=' '):\n",
        "        super().__init__(tok, rules=rules, counter=counter,\n",
        "                 lengths=lengths, mode=mode, sep=sep)\n",
        "    \n",
        "    @classmethod\n",
        "    @delegates(tokenize_folderOP, keep=True)\n",
        "    def from_folder(cls, path, tok=None, rules=None, output_dir = None, **kwargs):\n",
        "        path = Path(path)\n",
        "        if tok is None: tok = WordTokenizer()\n",
        "        output_dir = tokenize_folderOP(path, tok=tok, rules=rules, \n",
        "                                       skip_if_exists = False, \n",
        "                                       output_dir = output_dir, **kwargs)\n",
        "        res = cls(tok, counter=load_pickle(output_dir/fn_counter_pkl),\n",
        "                  lengths=load_pickle(output_dir/fn_lengths_pkl),\n",
        "                  rules=rules, mode='folder')\n",
        "        res.path,res.output_dir = path,output_dir\n",
        "        return res\n",
        "\n",
        "\n",
        "class TextBlockOP(TextBlock):\n",
        "    \"Overriding TextBlock for user defined output dir\"\n",
        "    def __init__(self, tok_tfm, vocab=None, is_lm=False,\n",
        "                 seq_len=72, backwards=False, **kwargs):\n",
        "        super().__init__(tok_tfm, vocab=vocab, is_lm=is_lm,\n",
        "                 seq_len=seq_len, backwards=backwards, **kwargs)\n",
        "    @classmethod\n",
        "    @delegates(TokenizerOP.from_folder, keep=True)\n",
        "    def from_folder(cls, path, vocab=None, is_lm=False, seq_len=72,\n",
        "                    backwards=False, min_freq=3, max_vocab=60000,output_dir =None,\n",
        "                    **kwargs):\n",
        "        \"Build a `TextBlock` from a `path` - calls TokenizerOP and provides output_dir as input\"\n",
        "        return cls(TokenizerOP.from_folder(path, output_dir = output_dir, **kwargs), vocab=vocab, is_lm=is_lm, seq_len=seq_len,\n",
        "                   backwards=backwards, min_freq=min_freq, max_vocab=max_vocab)\n",
        "        \n",
        "class TextDataLoadersOP(TextDataLoaders):\n",
        "    \"Basic wrapper around several `DataLoader`s with factory methods for NLP problems\"\n",
        "    @classmethod\n",
        "    @delegates(DataLoaders.from_dblock)\n",
        "    def from_folder(cls, path, train='train', valid='valid', valid_pct=None,\n",
        "                    seed=None, vocab=None, text_vocab=None, is_lm=False,\n",
        "                    tok_tfm=None, seq_len=72, splitter=None,\n",
        "                    backwards=False, output_dir =None, **kwargs):\n",
        "        \"This is to override same method from TextDataLoaders to accept and pass output_dir as input\"\n",
        "        if splitter is None:\n",
        "            splitter = GrandparentSplitter(train_name=train,\n",
        "                                           valid_name=valid) if valid_pct is None else RandomSplitter(valid_pct,\n",
        "                                                                                                      seed=seed)\n",
        "        blocks = [TextBlockOP.from_folder(path, text_vocab, is_lm, seq_len, backwards,\n",
        "                                          tok=tok_tfm, output_dir = output_dir)]\n",
        "        if not is_lm: blocks.append(CategoryBlock(vocab=vocab))\n",
        "        get_items = partial(get_text_files, folders=[train,valid]) if valid_pct is None else get_text_files\n",
        "        dblock = DataBlock(blocks=blocks,\n",
        "                           get_items=get_items,\n",
        "                           splitter=splitter,\n",
        "                           get_y=None if is_lm else parent_label)\n",
        "        return cls.from_dblock(dblock, path, path=path, seq_len=seq_len, **kwargs)\n"
      ],
      "metadata": {
        "id": "a32FvSRrp02R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok_path = model_save_path / 'train_tok'\n",
        "tok_path.mkdir(parents=True, exist_ok=True)\n",
        "dls_lm = TextDataLoadersOP.from_folder(path / 'train', is_lm=True,\n",
        "                                       valid_pct=0.1, output_dir = tok_path)\n",
        "# TextDataLoaders.from_folder(path / 'train', is_lm=True, valid_pct=0.1, )\n",
        "dls_lm.show_batch(max_n=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "mp9oSroFS1Ub",
        "outputId": "74393eb4-4679-4f08-8434-de841594c1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              ""
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj in xxmaj german suburb , this is a \" car - free \" place , this may seem shocking to many for people who use cars to go where they need to everyday …  ▁ xxmaj car ownership is only allowed in two places ; large parking garages at the edge of development , where a car owner buys a space , for $ 40 , xxrep 3 0 ,</td>\n",
              "      <td>xxmaj in xxmaj german suburb , this is a \" car - free \" place , this may seem shocking to many for people who use cars to go where they need to everyday …  ▁ xxmaj car ownership is only allowed in two places ; large parking garages at the edge of development , where a car owner buys a space , for $ 40 , xxrep 3 0 , along</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a home . vauban , home to 5,500 residents within a rectangular square mile , is the most advanced experiment in low car suburban life . \" all of our development since xxmaj world xxmaj war xxup ii has been centered on the car , and that will have to change , \" said david goldberg . xxbos dear , senator \\n\\n i think we should in take concideration in the next</td>\n",
              "      <td>home . vauban , home to 5,500 residents within a rectangular square mile , is the most advanced experiment in low car suburban life . \" all of our development since xxmaj world xxmaj war xxup ii has been centered on the car , and that will have to change , \" said david goldberg . xxbos dear , senator \\n\\n i think we should in take concideration in the next few</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>so he or she could go to the field trip . \\n\\n xxmaj those were my reason why is policy 1 is better than policy number 2 . xxbos xxmaj after reading this controversial essay on xxmaj electoral xxmaj college and how it affects other and our \" american xxmaj people \" i feel personally a bit ashamed at our own country that we allow all this nonsense to have happened .</td>\n",
              "      <td>he or she could go to the field trip . \\n\\n xxmaj those were my reason why is policy 1 is better than policy number 2 . xxbos xxmaj after reading this controversial essay on xxmaj electoral xxmaj college and how it affects other and our \" american xxmaj people \" i feel personally a bit ashamed at our own country that we allow all this nonsense to have happened . xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>growing up with social problems , such as depression , or suicidal thoughts , \" . xxmaj looking at this , it shows that we are still helping people break free , and really live their lives , the others may just need more help with meeting new people . xxmaj everyone can do it , it just might take more time for others . \\n\\n xxmaj overall , i feel that</td>\n",
              "      <td>up with social problems , such as depression , or suicidal thoughts , \" . xxmaj looking at this , it shows that we are still helping people break free , and really live their lives , the others may just need more help with meeting new people . xxmaj everyone can do it , it just might take more time for others . \\n\\n xxmaj overall , i feel that i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>to be a compromise between election of the xxmaj president by a vote in xxmaj congress and election of the xxmaj president by a popular vote of qualified citizens . xxmaj the xxmaj electoral xxmaj college consists of the meeting of electors where they vote for xxmaj president and xxmaj vice xxmaj president , and the counting of electoral votes by congress . \\n\\n xxmaj doing away with the xxmaj electoral xxmaj</td>\n",
              "      <td>be a compromise between election of the xxmaj president by a vote in xxmaj congress and election of the xxmaj president by a popular vote of qualified citizens . xxmaj the xxmaj electoral xxmaj college consists of the meeting of electors where they vote for xxmaj president and xxmaj vice xxmaj president , and the counting of electoral votes by congress . \\n\\n xxmaj doing away with the xxmaj electoral xxmaj xxunk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dump vocab that will be required for inference script\n",
        "with open(model_save_path / 'dls_lm_vocab.pickle', 'wb') as b:\n",
        "    pickle.dump(dls_lm.vocab,b)"
      ],
      "metadata": {
        "id": "5nDI4aAwaVp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn_lm = language_model_learner(dls_lm, AWD_LSTM, metrics=[accuracy, Perplexity()], path=path, wd=0.1).to_fp16()"
      ],
      "metadata": {
        "id": "3bcGSEuCTRrk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "03cf6e03-52f3-4269-e8e2-8f5ebef0edb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='105070592' class='' max='105067061' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [105070592/105067061 00:08&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn_lm.fit_one_cycle(1, 1e-2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ohXZDqkFTYrm",
        "outputId": "d444f308-39bb-4698-97fa-cac962c4e994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.766937</td>\n",
              "      <td>3.447428</td>\n",
              "      <td>0.324247</td>\n",
              "      <td>31.419462</td>\n",
              "      <td>01:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn_lm.unfreeze()\n",
        "learn_lm.fit_one_cycle(10, 1e-3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "KE1k8a1xTgNG",
        "outputId": "6efe3904-927f-4192-95a4-18897cd068b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-780f195b1adb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlearn_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'learn_lm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path.mkdir(parents=True, exist_ok=True)\n",
        "if iskaggle:\n",
        "    # hack to save encoder in a writable location\n",
        "    learn_lm.path = model_save_path\n",
        "    learn_lm.save_encoder('finetuned_enc')\n",
        "    # learn_lm.save('finetuned_lm')\n",
        "else:\n",
        "    learn_lm.save_encoder(model_save_path / 'finetuned_enc')"
      ],
      "metadata": {
        "id": "VBxJGBQCXhei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text classification"
      ],
      "metadata": {
        "id": "_WyXQ4ySSyUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def file_read(file_path):\n",
        "    with open(file_path, 'r') as _f: \n",
        "        all_content = _f.read()\n",
        "    return all_content"
      ],
      "metadata": {
        "id": "DaZzI-zTqNSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process text - add all columns \n",
        "df = pd.read_csv(path/'train.csv')\n",
        "df['essay_text'] = df['essay_id'].apply(lambda x: file_read(path / 'train' / f'{x}.txt'))\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        },
        "id": "XY6PVulLoZFY",
        "outputId": "1f2da6cf-221d-4c30-c189-9f76c22ba54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   discourse_id      essay_id  \\\n",
              "0  0013cc385424  007ACE74B050   \n",
              "1  9704a709b505  007ACE74B050   \n",
              "2  c22adee811b6  007ACE74B050   \n",
              "3  a10d361e54e4  007ACE74B050   \n",
              "4  db3e453ec4e2  007ACE74B050   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                               discourse_text  \\\n",
              "0                                               Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform.    \n",
              "1                                                                                                                                                          On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform    \n",
              "2                                                                                                                                                                                                                                                                   I think that the face is a natural landform because there is no life on Mars that we have descovered yet    \n",
              "3  If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says in paragraph 9, \"It's not easy to target Cydonia,\" in which he is saying that its not easy to know if it is a natural landform at this point. In all that they're saying, its probably a natural landform.    \n",
              "4                                                                                                                                                                                                                                                                       People thought that the face was formed by alieans because they thought that there was life on Mars.    \n",
              "\n",
              "  discourse_type discourse_effectiveness  \\\n",
              "0           Lead                Adequate   \n",
              "1       Position                Adequate   \n",
              "2          Claim                Adequate   \n",
              "3       Evidence                Adequate   \n",
              "4   Counterclaim                Adequate   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                essay_text  \n",
              "0  Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...  \n",
              "1  Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...  \n",
              "2  Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...  \n",
              "3  Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...  \n",
              "4  Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0075dd2a-c306-4355-a2e3-6245d7c34fd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>essay_id</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_effectiveness</th>\n",
              "      <th>essay_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0013cc385424</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform.</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9704a709b505</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform</td>\n",
              "      <td>Position</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c22adee811b6</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>I think that the face is a natural landform because there is no life on Mars that we have descovered yet</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a10d361e54e4</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says in paragraph 9, \"It's not easy to target Cydonia,\" in which he is saying that its not easy to know if it is a natural landform at this point. In all that they're saying, its probably a natural landform.</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>db3e453ec4e2</td>\n",
              "      <td>007ACE74B050</td>\n",
              "      <td>People thought that the face was formed by alieans because they thought that there was life on Mars.</td>\n",
              "      <td>Counterclaim</td>\n",
              "      <td>Adequate</td>\n",
              "      <td>Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0075dd2a-c306-4355-a2e3-6245d7c34fd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0075dd2a-c306-4355-a2e3-6245d7c34fd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0075dd2a-c306-4355-a2e3-6245d7c34fd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See sequence length\n",
        "df['seq_length_essay'] = [len(txt.split()) for txt in df['essay_text'].tolist()]\n",
        "df['seq_length_dis'] = [len(txt.split()) for txt in df['discourse_text'].tolist()]\n",
        "df['seq_length_essay'].describe(), df['seq_length_dis'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k__FA3GVwqeI",
        "outputId": "a1564748-1e6a-422b-c211-f1a5aa389ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(count    36765.000000\n",
              " mean       458.588522\n",
              " std        220.423420\n",
              " min        144.000000\n",
              " 25%        288.000000\n",
              " 50%        408.000000\n",
              " 75%        579.000000\n",
              " max       1367.000000\n",
              " Name: seq_length_essay, dtype: float64, count    36765.000000\n",
              " mean        44.654073\n",
              " std         46.669682\n",
              " min          1.000000\n",
              " 25%         16.000000\n",
              " 50%         28.000000\n",
              " 75%         57.000000\n",
              " max        836.000000\n",
              " Name: seq_length_dis, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# replace discorse text within the context text as __MASKED__\n",
        "df['masked_ess_txt'] = df[['essay_text','discourse_text']].apply(lambda row: row.essay_text.strip().replace(row.discourse_text.strip(),\n",
        "                                                                                                         '__MASKED__'),\n",
        "                                                              axis = 1)\n",
        "df['seq_length_mask_ess'] = [len(txt.split()) for txt in df['masked_ess_txt'].tolist()]\n",
        "df['masked_ess_txt'].head(), df['seq_length_mask_ess'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSq5YwUFHsgH",
        "outputId": "5bec9631-dbaf-48b3-d351-49a580096b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0    __MASKED__ On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no life on Mars that we have descovered yet. If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says in paragraph 9, \"It's not easy to target Cydonia,\" in which he is saying that its not easy to know if it is...\n",
              " 1    Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. __MASKED__\\n\\nI think that the face is a natural landform because there is no life on Mars that we have descovered yet. If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says ...\n",
              " 2    Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\n__MASKED__. If life was on Mars, we would know by now. The reason ...\n",
              " 3    Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...\n",
              " 4    Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I'll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no li...\n",
              " Name: masked_ess_txt, dtype: object, count    36765.000000\n",
              " mean       414.791024\n",
              " std        213.788307\n",
              " min          1.000000\n",
              " 25%        254.000000\n",
              " 50%        367.000000\n",
              " 75%        531.000000\n",
              " max       1345.000000\n",
              " Name: seq_length_mask_ess, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to truncate discourse text and context text\n",
        "# this is still in progress\n",
        "# def trunc_text(text, num_words, unique_centre_tok = None):\n",
        "#     w_l = text.split()\n",
        "#     if unique_centre_tok is None:\n",
        "#         if len(w_l) > num_words: w_l = w_l[:num_words]\n",
        "#     else:\n",
        "#         if len(w_l) > num_words:\n",
        "#             try: pos_tok = w_l.index(unique_centre_tok) + 1\n",
        "#             except: # in case there is an issue with the replacement\n",
        "#                 print(text)\n",
        "#                 pos_tok = round(num_words / 2)\n",
        "#             if pos_tok > round(len(w_l) / 2):\n",
        "#                 if len(w_l) > pos_tok + round((num_words - 1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words - 1) / 2) - 1\n",
        "#                 else:\n",
        "#                     start_pos = len(w_l) - num_words\n",
        "#                 w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#             else:\n",
        "#                 if pos_tok > round((num_words -1) / 2):\n",
        "#                     start_pos = pos_tok - round((num_words -1) / 2) - 1\n",
        "#                     w_l = w_l[start_pos:(start_pos + num_words)]\n",
        "#                 else:\n",
        "#                     w_l = w_l[:num_words]\n",
        "            \n",
        "#     return ' '.join(w_l)\n",
        "\n",
        "# [trunc_text(\"let's see where __MASKED__ we are going.\", i, unique_centre_tok = \"__MASKED__\") for i in range(2,8)]"
      ],
      "metadata": {
        "id": "VFLhCiRbrWKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all text columns for classification \n",
        "# concat all\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text + '; DISCOURSE: ' + df.discourse_text + '; TYPE: ' + df.discourse_type\n",
        "\n",
        "# concat after truncation\n",
        "# df['essay_text_trunc'] = df.masked_ess_txt.apply(lambda t: trunc_text(t,512, \"__MASKED__\"))\n",
        "# df['discourse_text_trunc'] = df.discourse_text.apply(lambda t: trunc_text(t,64))\n",
        "# df['all_text'] = 'CONTEXT: ' + df.essay_text_trunc + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text_trunc \n",
        "df['all_text'] = 'CONTEXT: ' + df.masked_ess_txt + '; TYPE: ' + df.discourse_type + '; DISCOURSE: ' + df.discourse_text\n",
        "df['seq_length_all'] = [len(txt.split()) for txt in df['all_text'].tolist()]\n",
        "df['seq_length_all'].describe()"
      ],
      "metadata": {
        "id": "xy67RMN42OSI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8bbae23-1b9b-478a-99fe-eb9f711e2ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    36765.000000\n",
              "mean       463.536244\n",
              "std        220.382475\n",
              "min        149.000000\n",
              "25%        293.000000\n",
              "50%        413.000000\n",
              "75%        584.000000\n",
              "max       1373.000000\n",
              "Name: seq_length_all, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create data loaders\n",
        "dls = TextDataLoaders.from_df(df, text_col='all_text',\n",
        "                              label_col='discourse_effectiveness',\n",
        "                            #   seq_len=600,\n",
        "                              text_vocab=dls_lm.vocab)\n",
        "dls.show_batch(max_n=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "SpWa5edK5ac1",
        "outputId": "51358f6d-e462-49c7-8e52-b7d711b61a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-713b2781b8e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create data loaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m dls = TextDataLoaders.from_df(df, text_col='all_text',\n\u001b[0m\u001b[1;32m      3\u001b[0m                               \u001b[0mlabel_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'discourse_effectiveness'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0;31m#   seq_len=600,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               text_vocab=dls_lm.vocab)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TextDataLoaders' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = text_classifier_learner(dls, AWD_LSTM, \n",
        "                                drop_mult=0.5,\n",
        "                                backwards=False,\n",
        "                                metrics=[accuracy,F1Score(average='weighted')]).to_fp16()\n",
        "# load encoder from language model\n",
        "if iskaggle: model_save_path = model_save_path / 'models'\n",
        "learn = learn.load_encoder(model_save_path / 'finetuned_enc')"
      ],
      "metadata": {
        "id": "yHF2TJZT74gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.lr_find(suggest_funcs=(valley, slide))"
      ],
      "metadata": {
        "id": "pxVOMs9zYHHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fine_tune(1, 0.01)"
      ],
      "metadata": {
        "id": "G2KpNDQf9FYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path.mkdir(parents=True, exist_ok=True)\n",
        "# learn.export(f'{model_save_path}/all_col_concat_learner.pkl')\n",
        "learn.save(f'{model_save_path}/all_text_concat_ulmfit_save.pkl')"
      ],
      "metadata": {
        "id": "Ax5UQ4TAPm8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test submission"
      ],
      "metadata": {
        "id": "xqlFEkilBkW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(path/'test.csv')\n",
        "# pre-process test df texts\n",
        "test_df['essay_text'] = test_df['essay_id'].apply(lambda x: file_read(path / 'test' / f'{x}.txt'))\n",
        "test_df['masked_ess_txt'] = test_df[['essay_text','discourse_text']].apply(lambda row: row.essay_text.strip().replace(row.discourse_text.strip(),\n",
        "                                                                                                         '__MASKED__'),\n",
        "                                                              axis = 1)\n",
        "# test_df['essay_text_trunc'] = test_df.masked_ess_txt.apply(lambda t: trunc_text(t,512,'__MASKED__'))\n",
        "# test_df['discourse_text_trunc'] = test_df.discourse_text.apply(lambda t: trunc_text(t,64))\n",
        "test_df['text'] = 'CONTEXT: ' + test_df.masked_ess_txt + '; TYPE: ' + test_df.discourse_type + '; DISCOURSE: ' + test_df.discourse_text "
      ],
      "metadata": {
        "id": "gjJvftl_U8CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df.rename(columns = {'discourse_text':'text'}, inplace = True)\n",
        "test_df.info()"
      ],
      "metadata": {
        "id": "WJszwQGq-hcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tst_dl = dls.test_dl(test_df)\n",
        "tst_dl.show_batch()"
      ],
      "metadata": {
        "id": "2nshwnkyCMXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
        "probs"
      ],
      "metadata": {
        "id": "NU0WAzprCSja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# column names for probabilities\n",
        "probs_df = pd.DataFrame(probs.numpy(),columns = dls.vocab[1])\n",
        "probs_df"
      ],
      "metadata": {
        "id": "M9m21njOEF9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs_df[\"discourse_id\"] = test_df[\"discourse_id\"]\n",
        "probs_df.to_csv('submission.csv', index=False)\n",
        "!head submission.csv"
      ],
      "metadata": {
        "id": "WtpR0ynUCY-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# not working for this competetion\n",
        "# if not iskaggle:\n",
        "#     from kaggle import api\n",
        "#     api.competition_submit_cli('submission.csv', 'initial', comp)"
      ],
      "metadata": {
        "id": "BCHJJtmoCkX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not iskaggle:\n",
        "    push_notebook('saan', comp,\n",
        "                  title='Feedback effeciveness: centre context full ulmfit',\n",
        "                  file='/content/drive/MyDrive/Colab Notebooks/all_text_concat_ulmfit_model.ipynb',\n",
        "                  competition=comp, private=False, gpu=True)"
      ],
      "metadata": {
        "id": "3DYHPZlGaaV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb65c4c7-087f-46fb-cba5-485ae20fc45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your kernel title does not resolve to the specified id. This may result in surprising behavior. We suggest making your title something that resolves to the specified id. See https://en.wikipedia.org/wiki/Clean_URL#Slug for more information on how slugs are determined.\n",
            "Kernel version 1 successfully pushed.  Please check progress at https://www.kaggle.com/code/saansd2003/feedback-effeciveness-centre-context-full-ulmfit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Rxb5R3vYbLaw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}